{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# and, or, not - boolean operators\n",
    "stop_words.remove('and')\n",
    "stop_words.remove('or')\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(filename,file):\n",
    "    filename = os.path.join('./pickle',filename)\n",
    "    out = open(filename, 'wb')\n",
    "    pickle.dump(file, out)\n",
    "    out.close()\n",
    "    \n",
    "def load_pickle_data(file):\n",
    "    file = os.path.join('./pickle',file)\n",
    "    out = open(file, 'rb')\n",
    "    index_dict = pickle.load(out)\n",
    "    out.close()\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_metadata(lines):\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            start = i + 1\n",
    "            break\n",
    "    return lines[start:]\n",
    "\n",
    "\n",
    "\n",
    "def process_text(lines, index_dict,doc_ID):\n",
    "    lines = remove_metadata(lines)\n",
    "    seperator = ' '\n",
    "    file = seperator.join(lines)\n",
    "    words = word_tokenize(file)\n",
    "    words = process_words(words)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index_dict.keys():\n",
    "            if doc_ID not in index_dict[word]:\n",
    "                index_dict[word].append(doc_ID)\n",
    "        else:\n",
    "            index_dict[word] = [doc_ID]\n",
    "    \n",
    "    return index_dict\n",
    "            \n",
    "                \n",
    "def process_words(words):\n",
    "    mod_words = []\n",
    "    symbols = [ \"'\",'/','.','-','!','@','#','$','^','&','*','(',')','+']\n",
    "    #words = [word.replace(sym,'') for word in words for sym in symbols if sym in word]\n",
    "    removed_symbols = []\n",
    "    for word in words :\n",
    "        for sym in symbols:\n",
    "            if sym in word:\n",
    "                word = word.replace(sym,'')\n",
    "        removed_symbols.append(word)\n",
    "        \n",
    "    words = removed_symbols\n",
    "    del removed_symbols\n",
    "        \n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word.isalnum():\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            if word not in stop_words and len(word) >= 2:\n",
    "                mod_words.append(word)\n",
    "    return mod_words\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "file_mapper = {}\n",
    "root_dir = 'data'\n",
    "doc_ID = 1\n",
    "index_dict = {}\n",
    "for fol in os.listdir(root_dir): # for each folder\n",
    "    print(fol)\n",
    "    path = os.path.join(root_dir,fol) \n",
    "    for file in os.listdir(path): # for each file in folder\n",
    "        file_path = os.path.join(path, file)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            file_mapper[doc_ID] = file_path\n",
    "            index_dict = process_text(lines, index_dict,doc_ID)\n",
    "            doc_ID += 1\n",
    "pickle_data('index_dict.pkl',index_dict)\n",
    "pickle_data('index_file_mapper.pkl',file_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading index dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = load_pickle_data('index_dict.pkl')\n",
    "file_mapper = load_pickle_data('index_file_mapper.pkl')\n",
    "doc_ID = len(file_mapper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_merge(post_list1, post_list2):\n",
    "\n",
    "    \n",
    "    ans = []\n",
    "    ptr1 = 0 ; ptr2 = 0\n",
    "    comparisons = 0\n",
    "    while ptr1 < len(post_list1) and ptr2 < len(post_list2):\n",
    "        \n",
    "        if post_list1[ptr1] == post_list2[ptr2]:\n",
    "            ans.append(post_list1[ptr1])\n",
    "            ptr1 += 1\n",
    "            ptr2 += 1\n",
    "        elif post_list1[ptr1] < post_list2[ptr2] :\n",
    "            ptr1 += 1\n",
    "        else :\n",
    "            ptr2 += 1\n",
    "        comparisons += 1\n",
    "    return ans, comparisons\n",
    "\n",
    "def or_merge(post_list1, post_list2):\n",
    "\n",
    "    ans = []\n",
    "    ptr1 = 0 ; ptr2 = 0\n",
    "    comparisons = 0\n",
    "    while ptr1 < len(post_list1) and ptr2 < len(post_list2):\n",
    "\n",
    "        if post_list1[ptr1] == post_list2[ptr2]:\n",
    "            ans.append(post_list1[ptr1])\n",
    "            ptr1 += 1\n",
    "            ptr2 += 1\n",
    "        elif post_list1[ptr1] < post_list2[ptr2] :\n",
    "            ans.append(post_list1[ptr1])\n",
    "            ptr1 += 1\n",
    "        else :\n",
    "            ans.append(post_list2[ptr2])\n",
    "            ptr2 += 1\n",
    "        comparisons += 1\n",
    "        \n",
    "    while(ptr1 < len(post_list1)):\n",
    "        ans.append(post_list1[ptr1])\n",
    "        ptr1 += 1\n",
    "\n",
    "    while(ptr2 < len(post_list2)):\n",
    "        ans.append(post_list2[ptr2])\n",
    "        ptr2 += 1\n",
    "        \n",
    "    return ans, comparisons\n",
    "\n",
    "\n",
    "def not_merge(post_list1,doc_ID):\n",
    "    result = []\n",
    "    for doc in range(1,doc_ID):\n",
    "        if doc not in post_list1 :\n",
    "            result.append(doc)\n",
    "\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list(term,temp_results):\n",
    "    ans = []\n",
    "    if term in index_dict.keys():\n",
    "        ans = index_dict[term]\n",
    "    elif term in temp_results.keys():\n",
    "        ans = temp_results[term]\n",
    "    else :\n",
    "        print('Postings list is not there for given term ')\n",
    "    return ans\n",
    "\n",
    "\n",
    "def processing_not_operator(query):\n",
    "    temp_results = {}\n",
    "    ind = 0\n",
    "    i = len(query) - 1\n",
    "    while i >= 0:\n",
    "        if query[i] == 'not' :\n",
    "            if query[i-1] == 'not':\n",
    "                del query[i]\n",
    "                del query[i-1]\n",
    "                i -= 1\n",
    "            else:\n",
    "                term = query[i+1]\n",
    "                post_list = retrieve_list(term,temp_results)\n",
    "                key = 'result'+str(ind)\n",
    "                ind += 1\n",
    "                result = not_merge(post_list,doc_ID)\n",
    "                temp_results[key] = result\n",
    "\n",
    "                query[i] = key\n",
    "                del query[i+1]\n",
    "        i -= 1\n",
    "    return query, temp_results, ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_MIX(query, temp_results, ind):\n",
    "    \n",
    "    comparisons = 0\n",
    "    while True:\n",
    "        \n",
    "        if 'and' in query:\n",
    "            index = query.index('and')\n",
    "            term1 = query[index-1]\n",
    "            term2 = query[index+1]\n",
    "\n",
    "            list1 = retrieve_list(term1, temp_results)\n",
    "            list2 = retrieve_list(term2, temp_results)\n",
    "\n",
    "            res,comp = and_merge(list1, list2)\n",
    "            comparisons += comp\n",
    "            key = 'result'+str(ind)\n",
    "            ind += 1\n",
    "            temp_results[key] = res\n",
    "            query[index] = key\n",
    "            del query[index-1]\n",
    "            del query[index] # because of re arrangement\n",
    "            print(query)\n",
    "            \n",
    "        else :\n",
    "            \n",
    "            query = [term for term in query if term != 'or']\n",
    "            while len(query) > 1:\n",
    "                term1 = query[0]\n",
    "                term2 = query[1]\n",
    "                list1 = retrieve_list(term1, temp_results)\n",
    "                list2 = retrieve_list(term2, temp_results)\n",
    "                \n",
    "                res,comp = or_merge(list1, list2)\n",
    "                comparisons += comp\n",
    "                \n",
    "                key = 'result'+str(ind)\n",
    "                ind += 1\n",
    "                temp_results[key] = res\n",
    "                query[0] = key\n",
    "                del query[1]\n",
    "            break\n",
    "    results = retrieve_list(query[0], temp_results)\n",
    "    return results,comparisons\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def all_and_operators(query):\n",
    "    ans = True\n",
    "    if 'or' in query :\n",
    "        ans = False\n",
    "    return ans\n",
    "            \n",
    "def find_minimum(lists):\n",
    "    \n",
    "    dummy = lists.copy()\n",
    "    pos1 = lists.index(min(lists))\n",
    "    del dummy[pos1]\n",
    "    sec_min = min(dummy)\n",
    "    pos2 = lists.index(sec_min)\n",
    "    \n",
    "    return pos1,pos2\n",
    "\n",
    "def optimised_AND(query, temp_results, ind):\n",
    "    results = []\n",
    "    comparisons = 0\n",
    "    if len(query) == 0 :\n",
    "        print('Nothing to Process')\n",
    "    else :\n",
    "        print('OPTIMISING AND OPERATION')\n",
    "        query = [term for term in query if term != 'and']\n",
    "        posts_length = []\n",
    "        for term in query:\n",
    "            posts_length.append(len(retrieve_list(term,temp_results)))\n",
    "        \n",
    "        while True :\n",
    "            \n",
    "            if len(query) == 1:\n",
    "                results = retrieve_list(query[0], temp_results)\n",
    "                break\n",
    "        \n",
    "            else :\n",
    "                print(posts_length)\n",
    "                pos1,pos2 = find_minimum(posts_length)\n",
    "                list1 = retrieve_list(query[pos1], temp_results)\n",
    "                list2 = retrieve_list(query[pos2], temp_results)\n",
    "                print('Performing AND between lists with length {} and {}'.format(len(list1),len(list2)))\n",
    "                \n",
    "                res,comp = and_merge(list1, list2)\n",
    "                comparisons += comp\n",
    "                key = 'result'+str(ind)\n",
    "                ind += 1\n",
    "                temp_results[key] = res\n",
    "                posts_length[pos1] = len(res)\n",
    "                query[pos1] = key\n",
    "                \n",
    "                del posts_length[pos2]\n",
    "                del query[pos2]\n",
    "    \n",
    "    return results,comparisons\n",
    "    \n",
    "def process_query(query):\n",
    "    \n",
    "    temp_results = {}\n",
    "    results = []\n",
    "    query = process_words(query)\n",
    "    print('***final query after preprocessing***')\n",
    "    print(query)\n",
    "    print('***Processing NOT Operator***')\n",
    "    query, temp_results, ind = processing_not_operator(query)\n",
    "    print(query)\n",
    "    \n",
    "    if all_and_operators(query) :\n",
    "        results,comparisons = optimised_AND(query,temp_results, ind)\n",
    "        \n",
    "    else :\n",
    "        print('**** MIX of AND - OR****')\n",
    "        results,comparisons = process_MIX(query, temp_results, ind)\n",
    "        \n",
    "    print('#####Total Comparisons : {}#####'.format(comparisons))\n",
    "    return results\n",
    "def print_results(results):\n",
    "    docs = len(results)\n",
    "    print('Total Docs Retrieved are : {}'.format(docs))\n",
    "    files = []\n",
    "    for id in results:\n",
    "        files.append(file_mapper[id])\n",
    "    return files   \n",
    "    \n",
    "def read_query():\n",
    "    query = input().split()\n",
    "    results = process_query(query)\n",
    "    files = print_results(results)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email and boy or not girl\n",
      "***final query after preprocessing***\n",
      "['email', 'and', 'boy', 'or', 'not', 'girl']\n",
      "***Processing NOT Operator***\n",
      "['email', 'and', 'boy', 'or', 'result0']\n",
      "**** MIX of AND - OR****\n",
      "['result1', 'or', 'result0']\n",
      "#####Total Comparisons : 22365#####\n",
      "Total Docs Retrieved are : 19841\n"
     ]
    }
   ],
   "source": [
    "files = read_query()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
